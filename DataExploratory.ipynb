{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from json import loads\n",
    "from datetime import datetime\n",
    "from unicodedata import normalize\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt):\n",
    "    return normalize('NFKD', txt)\\\n",
    "           .encode('ASCII', 'ignore')\\\n",
    "           .decode('utf-8')\\\n",
    "           .lower()\\\n",
    "           .strip()\n",
    "\n",
    "def find_estado(x, cep):\n",
    "    x = clean_txt(x)    \n",
    "    if not x:\n",
    "        return 'Não Informado'\n",
    "    else:\n",
    "        try:\n",
    "            ix = np.where(cep.values == clean_txt(x))[0][0]\n",
    "            return cep.iloc[ix].sigla.upper()\n",
    "        except:\n",
    "            return 'Estrangeiro'\n",
    "\n",
    "def clean_location(x, cep, sigla):\n",
    "    for s in sigla:\n",
    "        if s in x.split(' '):\n",
    "            return s.upper()\n",
    "    \n",
    "    for p in punctuation:\n",
    "        x = x.replace(p, '|')\n",
    "    \n",
    "    x = clean_txt(x).split('|')\n",
    "    if x == ['brasil'] or x == ['brazil']:\n",
    "        return 'Brasileiro sem Estado'\n",
    "    else:\n",
    "        estado = 'Estrangeiro'\n",
    "        for i in x:\n",
    "            if find_estado(i, cep) != 'Estrangeiro':\n",
    "                estado = find_estado(i, cep)\n",
    "    \n",
    "        return estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  loads(open('twitter.json', encoding=\"utf8\").read())\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['created_at', 'full_text', 'entities', 'user', 'retweet_count', 'favorite_count']\n",
    "candidates = ['fraudenasurnaseletronicas', 'LulaNoPrimeiroTurno', 'viraviraciro','17neles', 'elenao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[columns]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cep = pd.read_csv('estados+cidades.csv', delimiter='|', header=None, names=['estado', 'sigla', 'cidade'])\n",
    "cep = cep.applymap(lambda x: clean_txt(x))\n",
    "cep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigla = set(cep.sigla.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df.user.apply(lambda x: x['location'])\n",
    "df['estado'] = df.location.apply(lambda x: clean_location(x, cep, sigla))\n",
    "df['user'] = df.user.apply(lambda x: x['name'])\n",
    "df['entities'] = df.entities.apply(lambda x: ';'.join([i['text'] for i in x['hashtags']]))\n",
    "df['candidate'] = df.entities.apply(lambda x: next((i for i in candidates if i in clean_txt(x)), 'branco'))\n",
    "df['date'] = df.created_at.apply(lambda x : datetime.strptime(x,'%a %b %d %H:%M:%S +0000 %Y').strftime('%Y-%m-%d %H:%M:%S'))\n",
    "del df['created_at']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['candidate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"candidate\")['user'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"estado\")['user'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'][df.estado=='Estrangeiro'].apply(lambda x: clean_txt(x)).value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['date', 'user', 'candidate', 'estado', 'location', 'retweet_count', 'favorite_count', 'full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['candidate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = df.date.astype('datetime64')\n",
    "df.candidate = df.candidate.astype('category').cat.add_categories(['#17Neles', '#EleNão', '#FicaTemer', '#FraudeNasUrnasEletrônicas','#LulaNoPrimeiroTurno'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[columns].sort_values(['date']).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('dataset.json.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset2.csv', sep=';', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(';',',').drop(['full_text', 'user'], axis=1).to_csv('dataset2.csv', sep=';', index_label=\"twitter\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
